


1a)

Import dask.dataframe as dd
import matplotlib.pyplot as plt

# Load the data
df_by_distance = dd.read_csv('trips_by_distance.csv')
df_full_data = dd.read_csv('trips_full_data.csv')

# Preprocess the data to ensure the correct data types and handle missing values
df_by_distance['Week'] = df_by_distance['Week'].('int')
df_full_data['Week of Date'] = df_full_data['Week of Date'].astype('int')

# Fill missing values with mean 
df_by_distance = df_by_distance.fillna(df_by_distance.mean())
df_full_data = df_full_data.fillna(df_full_data.mean())

# Calculate the average number of people staying at home per week
avg_staying_home = df_full_data.groupby('Week of Date')['Population Staying at Home'].mean().compute()

# Calculate the average number of trips of 1-25 miles per week
df_full_data['Trips 1-25 Miles'] = df_full_data[['Number of Trips 1-3', 'Number of Trips 3-5', 'Number of Trips 5-10', 'Number of Trips 10-25']].sum(axis=1)
avg_travel_1_25_miles = df_full_data.groupby('Week of Date')['Trips 1-25 Miles'].mean().compute()

# Plot the histogram for the average number of people staying at home per week
avg_staying_home.plot(kind='bar', title='Average Number of People Staying at Home per Week')
plt.xlabel('Week of Date')
plt.ylabel('Average Population Staying at Home')
plt.show()

# Plot the histogram for the average number of trips per week in the 1-25 miles category
avg_travel_1_25_miles.plot(kind='bar', title='Average Number of Trips 1-25 Miles per Week')
plt.xlabel('Week of Date')
plt.ylabel('Average Number of Trips')
plt.show()





1b)


import dask.dataframe as dd
import matplotlib.pyplot as plt

# Load the dataset for 'trips_by_distance'
df_by_distance = dd.read_csv('trips_by_distance.csv')

# Filter the dataset for trips greater than 10 million for the 10-25 miles range
df_10_25 = df_by_distance[df_by_distance['Number of Trips 10-25'] > 10000000]

# Filter the dataset for trips greater than 10 million for the 50-100 miles range
df_50_100 = df_by_distance[df_by_distance['Number of Trips 50-100'] > 10000000]

# Compute the results to bring them into memory
df_10_25_computed = df_10_25.compute()
df_50_100_computed = df_50_100.compute()

# Scatterplot for 10-25 miles
plt.scatter(df_10_25_computed['Date'], df_10_25_computed['Number of Trips 10-25'])
plt.title('Number of Trips 10-25 Miles > 10 Million by Date')
plt.xlabel('Date')
plt.ylabel('Number of Trips')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Scatterplot for 50-100 miles
plt.scatter(df_50_100_computed['Date'], df_50_100_computed['Number of Trips 50-100'])
plt.title('Number of Trips 50-100 Miles > 10 Million by Date')
plt.xlabel('Date')
plt.ylabel('Number of Trips')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()




1c)

import dask.dataframe as dd
import matplotlib.pyplot as plt
import time
from dask.distributed import from sklearn.linear_model import LinearRegression

# Initialize a Dask client to manage parallel workers
client = Client()

# Define the number of processors to use for parallel computation
n_processors = [10, 20]

# Define a dictionary to hold computation times for different processor counts
n_processors_time = {}

# Load the datasets using Dask
df_by_distance = dd.read_csv('trips_by_distance.csv')
df_full_data = dd.read_csv('trips_full_data.csv')

# Preprocessing 
df_by_distance = df_by_distance.categorize(columns=['Week']).fillna(method='ffill')
df_full_data = df_full_data.categorize(columns=['Week of Date']).fillna(method='ffill')

# Task 1a: Calculations for the average number of people staying at home per week and trips of 1-25 miles
def calculate_1a(df_full_data):
    avg_staying_home = df_full_data.groupby('Week of Date')['Population Staying at Home'].mean().compute()
    # For 'Trips 1-25 Miles', sum the appropriate columns if needed
    df_full_data['Trips 1-25 Miles'] = df_full_data[['Trips 1-3 Miles', 'Trips 3-5 Miles', 'Trips 5-10 Miles', 'Trips 10-25 Miles']].sum(axis=1)
    avg_travel_1_25_miles = df_full_data.groupby('Week of Date')['Trips 1-25 Miles'].mean().compute()
    return avg_staying_home, avg_travel_1_25_miles

# Task 1b: Filtering trips greater than 10 million and scatterplot
def calculate_1b(df_by_distance):
    # Adjusting column names according to Dataset1
    df_10_25 = df_by_distance[df_by_distance['Number of Trips 10-25'] > 10000000].compute()
    df_50_100 = df_by_distance[df_by_distance['Number of Trips 50-100'] > 10000000].compute()
    return df_10_25, df_50_100

# Loop over processor counts and perform analysis for tasks 1a and 1b
for processor in n_processors:
    client.restart()  # Restart the client to clear the previous state
    client = Client(n_workers=processor, threads_per_worker=1)

    # Timing the combined analysis for task 1a and 1b
    start_time = time.time()

    # Run task 1a and 1b computations
    avg_staying_home, avg_travel_1_25_miles = calculate_1a(df_full_data)
    df_10_25, df_50_100 = calculate_1b(df_by_distance)

    # Visualize the results of task 1a
    avg_staying_home.plot(kind='bar', title=f'Average Number of People Staying at Home per Week - {processor} processors')
    plt.xlabel('Week of Date')
    plt.ylabel('Average Population Staying at Home')
    plt.show()

    avg_travel_1_25_miles.plot(kind='bar', title=f'Average Number of Trips 1-25 Miles per Week - {processor} processors')
    plt.xlabel('Week of Date')
    plt.ylabel('Average Number of Trips 1-25 Miles')
    plt.show()

    # Plot the results 
    plt.scatter(df_10_25['Date'], df_10_25['Number of Trips 10-25'], label='Trips 10-25 miles')
    plt.scatter(df_50_100['Date'], df_50_100['Number of Trips 50-100'], label='Trips 50-100 miles')
    plt.legend()
    plt.title(f'Trips Greater Than 10 Million - {processor} processors')
    plt.xlabel('Date')
    plt.ylabel('Number of Trips')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

    # Record the computation time
    end_time = time.time()
    n_processors_time[processor] = end_time - start_time

# Display computation times for different processor counts
for processor, time_taken in n_processors_time.items():
    print(f"Computation time with {processor} processors: {time_taken} seconds")




1d) 

import dask.dataframe as dd
from dask.diagnostics import ProgressBar
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Load the datasets
df_by_distance = dd.read_csv('Trips_By_Distance.csv')
df_full_data = dd.read_csv('Trips_Full_Data.csv')

with ProgressBar():
    week_32_by_distance = df_by_distance[df_by_distance['Week'] == 32][['Number of Trips 5-10', 'Number of Trips 10-25']].compute()
    week_32_full_data = df_full_data[df_full_data['Week of Date'] == 32][['Trips 1-25 Miles', 'Trips 25-100 Miles']].compute()

# Combine the DataFrames for the regression task
combined_df = week_32_by_distance.merge(week_32_full_data, left_index=True, right_index=True)

# Define the dependent variable and the independent variables
y = combined_df['Number of Trips 5-10'] + combined_df['Number of Trips 10-25']
X = combined_df[['Trips 1-25 Miles', 'Trips 25-100 Miles']]

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the Linear Regression model
model = LinearRegression()

# Fit the model on the training data
model.fit(X_train, y_train)

# Predict on the test data
y_pred = model.predict(X_test)

# Calculate the Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse}")

# Plots of the models performance
plt.scatter(X_test['Trips 1-25 Miles'], y_test, color='blue', label='Actual')
plt.scatter(X_test['Trips 1-25 Miles'], y_pred, color='red', label='Predicted')
plt.title('Predicted vs Actual Frequency of Trips')
plt.xlabel('Distance Traveled (1-25 Miles)')
plt.ylabel('Frequency of Trips')
plt.legend()
plt.show()
